{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the dataset and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- defining the Franke function\n",
    "def FrankeFunction(x,y):\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "    term3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "    return term1 + term2 + term3 + term4\n",
    "\n",
    "# --- Generating dataset\n",
    "n = 100 # the square root of the number of datapoints\n",
    "x, y = np.linspace(0,1,n), np.linspace(0,1,n)\n",
    "x, y = np.meshgrid(x, y)\n",
    "x = x.ravel()\n",
    "y = y.ravel()\n",
    "\n",
    "k = .01 # noise coefficient\n",
    "z = FrankeFunction(x,y) + k*np.random.randn(n**2) # target variable with standard normal noise\n",
    "\n",
    "X = np.column_stack((x,y))\n",
    "\n",
    "X_train, X_test, z_train, z_test = train_test_split(X, z, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring for Optimal Model Parameters from Gridsearch of Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500, Loss: 0.0057\n",
      "Epoch 200/500, Loss: 0.0024\n",
      "Epoch 300/500, Loss: 0.0018\n",
      "Epoch 400/500, Loss: 0.0015\n",
      "Epoch 500/500, Loss: 0.0013\n",
      "Test MSE: 0.0012\n"
     ]
    }
   ],
   "source": [
    "# Defining the neural network\n",
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RegressionNet, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)        # one hidden layer\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    # defining the forward pass\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.hidden(x))       # sigmoid activation\n",
    "        x = self.output(x)                      # 'identity' activation\n",
    "        return x\n",
    "\n",
    "# Defining the sizes of the layers\n",
    "input_size = X_train.shape[1] \n",
    "hidden_size = 50  \n",
    "output_size = 1  \n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = RegressionNet(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()                                        # using MSE as a cost function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)               # Using SGD with a learning rate of 0.1\n",
    "\n",
    "# Standardizing the data and convert it to Pytorch tensors\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "z_train_tensor = torch.tensor(z_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "z_test_tensor = torch.tensor(z_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Creating data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, z_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)           # batch size 32\n",
    "\n",
    "# Training loop\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for X_batch, z_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, z_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {train_loss:.4f}')\n",
    "\n",
    "\n",
    "# Evaluating the model on the test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor).squeeze()\n",
    "    test_loss = mean_squared_error(z_test, predictions)\n",
    "print(f'Test MSE: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with own implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the MSE as a function of the learning rate and saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the neural network\n",
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RegressionNet, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)        # one hidden layer\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    # defining the forward pass\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.hidden(x))       # sigmoid activation\n",
    "        x = self.output(x)                      # 'identity' activation\n",
    "        return x\n",
    "\n",
    "# Defining the sizes of the layers\n",
    "input_size = X_train.shape[1] \n",
    "hidden_size = 50  \n",
    "output_size = 1  \n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = RegressionNet(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()                                        # using MSE as a cost function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)               # Using SGD with a learning rate of 0.1\n",
    "\n",
    "# Standardizing the data and convert it to Pytorch tensors\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "z_train_tensor = torch.tensor(z_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "z_test_tensor = torch.tensor(z_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Creating data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, z_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)           # batch size 32\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "N = 200\n",
    "learning_rates = np.logspace(-4, -1, N)\n",
    "scores = np.zeros(N)\n",
    "for idx, lr in enumerate(learning_rates):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for X_batch, z_batch in train_loader:\n",
    "            optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, z_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {train_loss:.4f}')\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test_tensor).squeeze()\n",
    "        test_loss = mean_squared_error(z_test, predictions)\n",
    "\n",
    "    scores[idx] = test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Results/regression_pytorch_learning_rate.npy', scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fysstk3155",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
